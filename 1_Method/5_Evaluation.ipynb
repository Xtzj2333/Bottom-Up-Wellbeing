{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMBG9g2dk5uc"
   },
   "outputs": [],
   "source": [
    "here = '1_Method/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yEvZW3p5pfW6"
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RtVFl2T_pgo-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "def clustering_report(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute clustering metrics between ground-truth labels and cluster labels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like (pd.Series, list, np.ndarray)\n",
    "        Ground-truth class labels (can be strings or ints).\n",
    "    y_pred : array-like\n",
    "        Cluster assignments (can be strings or ints).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys: 'NMI', 'ACC', 'Purity', 'ARI'\n",
    "    \"\"\"\n",
    "    # Convert to pandas Series for easy NA handling\n",
    "    # reset index\n",
    "    y_true = pd.Series(y_true).reset_index(drop=True)\n",
    "    y_pred = pd.Series(y_pred).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    # Drop pairs with NA\n",
    "    mask = (~y_true.isna()) & (~y_pred.isna())\n",
    "    y_true = y_true[mask].to_numpy()\n",
    "    y_pred = y_pred[mask].to_numpy()\n",
    "\n",
    "    if y_true.size == 0:\n",
    "        raise ValueError(\"No valid (non-NA) label pairs to compare.\")\n",
    "\n",
    "    # Contingency table: rows=true classes, cols=predicted clusters\n",
    "    C = contingency_matrix(y_true, y_pred)  # shape: [n_true, n_pred]\n",
    "    N = C.sum()\n",
    "\n",
    "    # Purity: sum over clusters of majority true class proportion\n",
    "    purity = np.sum(C.max(axis=0)) / N\n",
    "\n",
    "    # ACC: maximize trace via Hungarian algorithm\n",
    "    try:\n",
    "        from scipy.optimize import linear_sum_assignment\n",
    "        row_ind, col_ind = linear_sum_assignment(-C)  # maximize\n",
    "        acc = C[row_ind, col_ind].sum() / N\n",
    "    except Exception:\n",
    "        # Greedy fallback if SciPy isn't available\n",
    "        C_work = C.copy().astype(float)\n",
    "        acc_sum = 0.0\n",
    "        used_rows, used_cols = set(), set()\n",
    "        while len(used_rows) < C.shape[0] and len(used_cols) < C.shape[1]:\n",
    "            i, j = np.unravel_index(np.argmax(C_work), C_work.shape)\n",
    "            if C_work[i, j] <= -1:  # exhausted\n",
    "                break\n",
    "            acc_sum += C[i, j]\n",
    "            used_rows.add(i); used_cols.add(j)\n",
    "            C_work[i, :] = -1\n",
    "            C_work[:, j] = -1\n",
    "        acc = acc_sum / N\n",
    "\n",
    "    # NMI & ARI\n",
    "    nmi = normalized_mutual_info_score(y_true, y_pred, average_method=\"arithmetic\")\n",
    "    ari = adjusted_rand_score(y_true, y_pred)\n",
    "\n",
    "    return {\"NMI\": float(nmi), \"ACC\": float(acc), \"Purity\": float(purity), \"ARI\": float(ari)}\n",
    "\n",
    "\n",
    "def evaluate(results):\n",
    "  report = pd.DataFrame()\n",
    "  for result in results:\n",
    "    # turn into dataframe\n",
    "    # add names\n",
    "    df = pd.DataFrame(result['params'], index=[0])\n",
    "    df['name'] = result['name']\n",
    "    metrics = clustering_report(result['df']['adj'], result['output']['topics'])\n",
    "    df['NMI'] = metrics['NMI']\n",
    "    df['ACC'] = metrics['ACC']\n",
    "    df['Purity'] = metrics['Purity']\n",
    "    df['ARI'] = metrics['ARI']\n",
    "    report = pd.concat([report, df])\n",
    "  return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbDjsKaJIGDX"
   },
   "outputs": [],
   "source": [
    "def search(results, params):\n",
    "    \"\"\"\n",
    "    Keep results where every key in `params` either:\n",
    "      - is missing in result['params'] (ignored), or\n",
    "      - exists and equals the requested value.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for r in results:\n",
    "        rp = r.get('params', {})\n",
    "        if all((k not in rp) or (rp[k] == v) for k, v in params.items()):\n",
    "            out.append(r)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqKOr8V-mMdV"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 77948,
     "status": "error",
     "timestamp": 1757272356985,
     "user": {
      "displayName": "Tony Liao",
      "userId": "13421491116072109086"
     },
     "user_tz": 240
    },
    "id": "Q-wByl01k6mZ",
    "outputId": "8ada095f-61f6-4808-ed8f-a91540b60a99"
   },
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(here + 'output/results_kmean2.pkl', 'rb') as f:\n",
    "    results_kmean_run1 = pkl.load(f)\n",
    "\n",
    "with open(here + 'output/results_hdbscan2.pkl', 'rb') as f:\n",
    "    results_hdbscan_run1 = pkl.load(f)\n",
    "\n",
    "with open(here + 'output/results_hdbscan3.pkl', 'rb') as f:\n",
    "    results_hdbscan_run2 = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyJUyaA7mXIV"
   },
   "outputs": [],
   "source": [
    "eval_run_1 = pd.concat([evaluate(results_kmean_run1), evaluate(results_hdbscan_run1)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNpMrkDl8cQplsg7x6d3BRV",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
